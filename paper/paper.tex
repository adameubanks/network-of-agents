\documentclass[sigconf]{aamas}
\PassOptionsToPackage{activate=false,expansion=false,protrusion=false,kerning=false}{microtype}
\usepackage{amsmath,amssymb}
\DisableLigatures{encoding = *, family = * }
\makeatletter
\@ifpackageloaded{microtype}{%
  \microtypesetup{activate=false,expansion=false,protrusion=false,kerning=false}
}{}
\makeatother

% Suppress font package warnings
\makeatletter
\@ifpackageloaded{libertine}{}{}
\@ifpackageloaded{inconsolata}{}{}
\@ifpackageloaded{newtxmath}{}{}
\makeatother
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{url}

\newcommand{\modelFiveNano}{gpt-5-nano}
\newcommand{\modelFiveMini}{gpt-5-mini}
\newcommand{\modelGrokMini}{grok-mini}
\newcommand{\Placeholder}{--}
\newcommand{\modelsCompared}{\modelFiveNano, \modelFiveMini, \modelGrokMini}

\title{Algorithmic Fidelity of Large Language Models in Multi-Agent Systems}

\author{Adam Eubanks}
\affiliation{
  \institution{Brigham Young University}
  \city{Provo}
  \state{UT}
  \country{USA}
}
\email{adameuba@byu.edu}

\author{Caelen Miller}
\affiliation{
  \institution{Brigham Young University}
  \city{Provo}
  \state{UT}
  \country{USA}
}
\email{cm725@byu.edu}

\author{Sean Warnick}
\affiliation{
  \institution{Brigham Young University}
  \city{Provo}
  \state{UT}
  \country{USA}
}
\email{sean@cs.byu.edu}

\begin{abstract}
We introduce \textit{algorithmic fidelity} as a framework for evaluating whether LLM-based multi-agent systems faithfully reproduce classical opinion dynamics. Our key finding: the specific LLMs we tested (GPT-5 and Grok) exhibit systematic biases that compromise their ability to serve as proxies for human opinion formation. We test this by comparing LLM-induced opinion dynamics to the mathematical DeGroot model across 10 topics, finding that these models consistently converge to negative opinions regardless of human polling baselines or mathematical predictions. The bias manifests as a 456:1 ratio of extreme negative to positive ratings, with symmetry violations ranging from 0.019 to 1.814 when reversing option order. These results suggest that the tested LLMs cannot be trusted for social simulation without significant calibration and validation, though broader conclusions require validation across additional model families.
\end{abstract}

\begin{document}

\maketitle

\keywords{multi-agent systems, opinion dynamics, large language models, algorithmic fidelity}

\section{Introduction}
Large language models (LLMs) are increasingly deployed in multi-agent systems for social simulation, yet their mathematical fidelity to classical opinion dynamics models remains largely unexplored. While the multi-agent systems community has extensively studied emergent behavior in agent-based systems \cite{epstein2007generative}, the integration of LLMs introduces fundamental challenges: these models may exhibit systematic biases that distort the intended mathematical dynamics, compromising the reliability of automated social influence systems.

The growing use of LLMs in social simulation raises a critical question: \textit{Can LLMs serve as faithful proxies for human opinion formation in multi-agent settings?} This question is not merely about content quality or task performance, but about whether LLMs preserve the mathematical structure that makes opinion dynamics predictable and controllable. We introduce \textbf{algorithmic fidelity} as a novel theoretical framework that quantifies how well LLM-induced opinion-dynamics operators reproduce the mathematical properties of classical models like DeGroot and Friedkin-Johnsen.

\textbf{Algorithmic Fidelity Framework:} Unlike traditional evaluation metrics that focus on individual task performance, algorithmic fidelity specifically measures whether LLMs preserve the fundamental mathematical structure of opinion dynamics—including convergence properties, equilibrium points, symmetry requirements, and network effects. This framework addresses a critical gap in MAS research: while LLMs are increasingly used for social simulation, there is no systematic way to assess whether they faithfully reproduce expected mathematical behavior.

The theoretical significance of algorithmic fidelity extends beyond academic curiosity. In applications involving opinion control and social influence, the mathematical properties of the underlying dynamics determine the feasibility and effectiveness of control strategies. If LLMs fail to preserve these properties, then control-theoretic approaches to social influence may not be applicable in LLM-based multi-agent systems. This has profound implications for the deployment of automated social influence systems in real-world settings.

\textbf{Research Questions:} We address three fundamental questions: (1) Do LLM agents reproduce classical opinion dynamics behavior across diverse network topologies? (2) Do they maintain mathematical symmetry under topic order reversal? (3) How large are the deviations in bias, convergence properties, and algorithmic fidelity across canonical experimental configurations?

\textbf{Experimental Design:} To ensure robust findings, we employ six canonical experimental configurations spanning diverse network topologies (Watts-Strogatz small-world, Barabási-Albert scale-free, Erdős-Rényi random, stochastic block models, Zachary's karate club, and Friedkin-Johnsen with stubbornness) and two classical opinion dynamics models (DeGroot and Friedkin-Johnsen). This comprehensive approach enables systematic evaluation of LLM behavior across well-established scenarios from the literature while maintaining cost efficiency through optimized network sizes.

\textbf{Contributions:}
\begin{itemize}
  \item Introduce algorithmic fidelity as a rigorous framework for evaluating LLM-based opinion dynamics
  \item Demonstrate systematic evaluation across six canonical network topologies and two opinion dynamics models
  \item Provide empirical evidence of algorithmic fidelity failures that compromise LLM reliability in social simulation
  \item Establish theoretical foundations for understanding LLM-induced operators and their mathematical properties
\end{itemize}

We next describe our experimental framework and canonical configurations (Methods), present systematic analysis of algorithmic fidelity failures (Results), and discuss theoretical implications for LLM-based social simulation (Discussion).

\section{Related Work}
\textbf{Automated Opinion Controllers:} The foundational work by DeBuse and Warnick (2024) \cite{debuse2024study} established the practical feasibility of using Large Language Models as automated agents in opinion dynamics. Their study introduced three archetypal controller types (stubborn, popular, and strategic agents) and demonstrated that LLMs can effectively translate numerical control signals into nuanced social media content. Critically, they showed that current generative AI technologies can both infer opinions from social media posts and generate appropriate responses based on quantified commands, making the implementation of automated social influence systems remarkably straightforward. However, their work focused on the \textit{capability} of LLMs to implement opinion controllers rather than their \textit{fidelity} to mathematical models.

\textbf{Multi-Agent Opinion Dynamics:} The DeGroot model provides the mathematical foundation for understanding opinion evolution in multi-agent systems \cite{degroot1974reaching,proskurnikov2017tutorial}. This model assumes linear update rules and has been extensively studied in control theory, social psychology, and multi-agent systems research. The linear DeGroot model remains a workhorse for mathematical analysis, with extensive results on convergence and network effects.

\textbf{LLM-based Multi-Agent Systems:} Recent work has explored using LLMs as agents in various multi-agent simulation contexts. Park et al. (2023) introduced "Generative Agents" that exhibit human-like behavior in virtual environments, while works from NeurIPS and ICLR workshops have explored LLM agents in social simulations. Parallel efforts study LLMs as evaluators, e.g., MT-Bench and G-Eval \cite{zheng2023judging,liu2023geval}, and propose multi-judge frameworks to reduce single-judge bias \cite{juries2024}. However, most studies focus on emergent behavior and task performance rather than algorithmic fidelity to mathematical models. The multi-agent systems community has shown increasing interest in LLM-based agents, but systematic evaluation of their mathematical consistency remains underexplored.

\textbf{Algorithmic Fidelity in AI Systems:} The concept of algorithmic fidelity (measuring how well computational agents reproduce expected mathematical behavior) has been explored in various contexts, including neural network approximation theory and AI safety evaluation. However, this concept has not been systematically applied to multi-agent opinion dynamics, representing a critical gap in the literature. Our work extends this concept to the domain of automated social influence systems, where fidelity to mathematical models is crucial for reliable deployment. We connect to the broader framing of algorithmic fidelity as discussed in Silicon Sampling \cite{wingate2024silicon}.

\textbf{LLM Bias and Alignment:} Extensive research has documented systematic biases in LLMs, including gender, racial, and political biases. However, the impact of these biases on multi-agent opinion dynamics and their interaction with network effects remains largely unexplored. Our work provides the first systematic analysis of how LLM biases manifest in multi-agent social dynamics, building on DeBuse and Warnick's framework to understand the limitations of automated opinion controllers.

\textbf{Ethical Considerations in Automated Social Influence:} DeBuse and Warnick (2024) \cite{debuse2024study} highlighted the ethical implications of automated opinion controllers, drawing on frameworks from biomedical research (Belmont Report) and cybersecurity (Menlo Report). They emphasized the need for responsible development and deployment of automated social influence systems. Our work contributes to this discussion by providing empirical evidence of algorithmic fidelity failures that could undermine the reliability and predictability of such systems.

\section{Mathematical Framework}
\subsection{Classical DeGroot Model}
In the classical DeGroot model, each agent $i$ has an opinion $x_i^{(t)} \in [0,1]$ at time $t$. The opinion update rule is:
\[
x_i^{(t+1)} = \sum_{j \in \mathcal{N}(i)} w_{ij} x_j^{(t)}
\]
where $\mathcal{N}(i)$ is the set of neighbors of agent $i$, and $w_{ij}$ are non-negative weights that sum to 1 for each agent.

\subsection{Friedkin-Johnsen Model}
The Friedkin-Johnsen model extends DeGroot by introducing stubbornness, where agents resist changing their opinions. The update rule is:
\[
x_i(t+1) = \lambda_i x_i(0) + (1-\lambda_i) \sum_{j \in \mathcal{N}(i)} w_{ij} x_j(t)
\]
where $\lambda_i \in [0,1]$ is the stubbornness parameter for agent $i$. When $\lambda_i = 0$, the agent behaves like in DeGroot; when $\lambda_i = 1$, the agent never changes its initial opinion. This model captures the realistic phenomenon that some individuals are more resistant to social influence than others.

\subsection{LLM-based Opinion Dynamics}
We extend the DeGroot model to include LLM-based text generation and interpretation. Each topic is framed as a comparison between two options (A vs B), allowing us to measure which side the LLM favors.

\textbf{Process:} Each timestep, agents (1) generate text posts based on their current opinion, (2) rate posts from neighbors, and (3) update their opinion based on received ratings. The LLM handles both text generation and rating, creating a closed-loop system where opinions evolve through LLM-mediated interactions.

\textbf{Scale Conversion:} We convert between the LLM's $[-1,1]$ scale and DeGroot's $[0,1]$ scale for comparison:
\[
x_{\text{math}} = \frac{x_{\text{agent}} + 1}{2}, \quad x_{\text{agent}} = 2x_{\text{math}} - 1
\]

\subsection{Algorithmic Fidelity Framework}
Algorithmic fidelity provides a rigorous framework for evaluating LLM-based multi-agent systems against classical mathematical models. We formalize this as follows:

\textbf{Mathematical Foundation:} Let $T: \mathbb{R}^n \to \mathbb{R}^n$ be the classical DeGroot operator defined by the influence matrix $W$, where $T(x) = Wx$. The LLM-based pipeline induces an operator $T_{\mathrm{LLM}}: \mathbb{R}^n \to \mathbb{R}^n$ through the composition of text generation, rating, and opinion updates. 

\textbf{Algorithmic Fidelity Definition:} We define algorithmic fidelity as the extent to which $T_{\mathrm{LLM}}$ preserves the mathematical properties of $T$. Specifically, let $\mathcal{P}$ denote the set of mathematical properties we wish to preserve (e.g., linearity, convergence, symmetry). Then algorithmic fidelity is measured as:
\[
\text{Fidelity} = \sum_{p \in \mathcal{P}} w_p \cdot \mathbb{I}[T_{\mathrm{LLM}} \text{ satisfies property } p]
\]
where $w_p$ are weights and $\mathbb{I}[\cdot]$ is an indicator function. Perfect algorithmic fidelity requires $T_{\mathrm{LLM}} \equiv T$ under identical network conditions, but we can also define partial fidelity based on which properties are preserved.

\textbf{Decomposition:} We decompose fidelity into two critical layers: (1) \textit{Measurement Layer:} How accurately do LLMs map between internal opinion representations and external text generation/interpretation? (2) \textit{Dynamics Layer:} How well do LLM-induced update operators approximate the mathematical properties of classical models?

\textbf{Theoretical Significance:} This framework addresses a fundamental question in MAS: Can LLMs serve as reliable proxies for human decision-making in multi-agent settings? Unlike traditional evaluation metrics that focus on individual task performance, algorithmic fidelity specifically measures whether LLMs preserve the mathematical structure that makes opinion dynamics predictable and controllable.

\textbf{Connection to Control Theory:} Algorithmic fidelity is particularly relevant for applications involving opinion control and social influence, where the mathematical properties of the underlying dynamics determine the feasibility and effectiveness of control strategies. If LLMs fail to preserve these properties, then control-theoretic approaches to social influence may not be applicable in LLM-based multi-agent systems.

\textbf{Relationship to Emergent Behavior:} While traditional MAS research focuses on emergent collective behaviors, algorithmic fidelity addresses a different question: whether the individual-level decision-making processes (as implemented by LLMs) are mathematically consistent with classical models. This is crucial for understanding whether LLM-based systems will exhibit the same emergent properties as their classical counterparts.

\subsection{Calibration Framework}
Calibration quantifies the measurement layer $o\!\to\!r$, i.e., how the LLM's numeric rating $r$ of a post matches the intended opinion $o$ used to generate it. Let $o \in [0,1]$ denote the intended opinion (obtained by mapping the agent-domain value from $[-1,1]$ via $(x+1)/2$), and let $r \in [0,1]$ be the LLM's numeric rating parsed from its interpretation of the post. Define the calibration function $g(o) = \mathbb{E}[r\mid o]$; perfect calibration corresponds to $g(o) = o$.

\textit{Data construction.} Opinions and ratings are logged in $[-1,1]$ and mapped to $[0,1]$ via $(x+1)/2$ and clipped to $[0,1]$. For each agent and timestep $t$, we pair the rating at time $t$ with the intended opinion from time $t-1$ (storage occurs after the update). Metrics are computed per topic and summarized across topics.

\textbf{Centered affine model (on $[0,1]$).} We fit
\[
r - 0.5 = \alpha_c + \beta_c\,(o - 0.5).
\]
Here $\alpha_c = g(0.5) - 0.5$ is the neutrality shift (systematic tilt at the center), and $\beta_c$ is the sensitivity (compression if $\beta_c<1$, amplification if $\beta_c>1$). We report $(\alpha_c,\beta_c)$, centered $R^2$, and the calibration error $\mathrm{RMSE}=\sqrt{\mathbb{E}[(r-o)^2]}$.

\section{Methods}
\subsection{Experimental Framework}
We introduce a rigorous experimental framework for evaluating algorithmic fidelity in LLM-based opinion dynamics through six canonical configurations drawn from the literature. Our approach systematically tests multiple opinion dynamics models, network topologies, and initialization methods to provide comprehensive insights into LLM behavior across diverse scenarios.

\textbf{System Architecture:} Our experimental system consists of four main components:

\textbf{1. Agent System:} Each agent $i$ maintains a current opinion $x_i^{(t)} \in [-1,1]$ and can generate posts and interpret others' posts through LLM-mediated interactions.

\textbf{2. LLM Client:} Handles communication with multiple LLM providers via the LiteLLM library, managing post generation and rating tasks with consistent prompting protocols.

\textbf{3. Simulation Controller:} Orchestrates the multi-agent simulation, managing opinion updates and network dynamics with support for both DeGroot and Friedkin-Johnsen models.

\textbf{4. Canonical Configuration System:} Provides literature-based parameter sets for reproducible experiments across six distinct network topologies and two opinion dynamics models.

\subsection{Prompt Design and Opinion Scale}
We use an A vs B axis framing to stabilize expression and enable symmetry tests. Exact post generation and rating prompts, parsing rules, and examples are provided in Appendix~\ref{app:prompts_parsing}. Opinions use a continuous scale from $-1$ to $1$, mapped to $[0, 1]$ for DeGroot comparisons.

\subsection{Simulation Protocol}
The simulation follows this exact protocol for each timestep $t$:

\textbf{Step 1: Post Generation}
\begin{enumerate}
  \item For each connected agent $i$ (degree $> 0$), generate a post using the post generation prompt
  \item Include up to 6 most recent neighbor posts as context (truncated to 220 characters each)
  \item Prefix each generated post with "Agent {i}:" for identification
\end{enumerate}

\textbf{Step 2: Post Rating}
\begin{enumerate}
  \item For each agent $i$ and each neighbor $j$ (where $A_{ij} = 1$), agent $i$ rates agent $j$'s post
  \item Use the rating prompt to extract a numeric value in $[-1, 1]$
  \item Parse the response using regex pattern matching to extract the last numeric value
  \item Clamp values to $[-1, 1]$ range
\end{enumerate}

\textbf{Step 3: Opinion Update}
\begin{enumerate}
  \item For each agent $i$, compute the mean rating received from neighbors:
  \[
  \bar{r}_i^{(t)} = \frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)} r_{j \to i}^{(t)}
  \]
  \item Convert to math domain $[0,1]$: $x_i^{(t)} = \frac{\bar{r}_i^{(t)} + 1}{2}$
  \item Apply DeGroot update: $x_i^{(t+1)} = \sum_{j} w_{ij} x_j^{(t)}$
  \item Convert back to agent domain $[-1,1]$: $x_i^{(t+1)} = 2x_i^{(t+1)} - 1$
\end{enumerate}

\textbf{Step 4: Pure DeGroot Comparison}
\begin{enumerate}
  \item Calculate what pure DeGroot would produce using the same initial conditions
  \item Compute divergence metrics (MAE, RMSE, correlation) between LLM and pure DeGroot results
\end{enumerate}

\subsection{Six Canonical Experimental Configurations}
We employ six canonical experimental configurations based on established literature in opinion dynamics and social networks. Each configuration represents a well-studied scenario that enables systematic comparison of LLM behavior against mathematical models while maintaining cost efficiency through optimized network sizes (N=50).

\textbf{Configuration 1: Watts-Strogatz Small-World Networks}
\begin{itemize}
  \item \textbf{Model:} DeGroot with standard parameters ($\epsilon = 10^{-6}$)
  \item \textbf{Network:} Watts-Strogatz small-world (N=50, k=4, $\beta$=0.1) \cite{watts1998collective}
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$) \cite{friedkin1990social}
  \item \textbf{Scale:} 50 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Watts \& Strogatz (1998) - captures real-world social clustering + short paths
\end{itemize}

\textbf{Configuration 2: Barabási-Albert Scale-Free Networks}
\begin{itemize}
  \item \textbf{Model:} DeGroot with standard parameters
  \item \textbf{Network:} Barabási-Albert scale-free (N=50, m=2) \cite{barabasi1999emergence}
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$)
  \item \textbf{Scale:} 50 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Barabási \& Albert (1999) - models influencer dynamics with power-law degree distribution
\end{itemize}

\textbf{Configuration 3: Erdős-Rényi Random Networks}
\begin{itemize}
  \item \textbf{Model:} DeGroot with standard parameters
  \item \textbf{Network:} Erdős-Rényi random (N=50, p=0.1) \cite{erdos1959random}
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$)
  \item \textbf{Scale:} 50 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Erdős \& Rényi (1959) - baseline random network for comparison
\end{itemize}

\textbf{Configuration 4: Stochastic Block Model (Echo Chambers)}
\begin{itemize}
  \item \textbf{Model:} DeGroot with standard parameters
  \item \textbf{Network:} Stochastic Block Model (N=50, 2 communities, p\_intra=0.3, p\_inter=0.05) \cite{holland1983stochastic}
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$)
  \item \textbf{Scale:} 50 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Holland et al. (1983) - creates echo chambers crucial for studying polarization
\end{itemize}

\textbf{Configuration 5: Zachary's Karate Club}
\begin{itemize}
  \item \textbf{Model:} DeGroot with standard parameters
  \item \textbf{Network:} Zachary's Karate Club (34 nodes, 78 edges) \cite{zachary1977information}
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$)
  \item \textbf{Scale:} 34 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Zachary (1977) - real empirical network validating against actual social structure
\end{itemize}

\textbf{Configuration 6: Friedkin-Johnsen with Stubbornness}
\begin{itemize}
  \item \textbf{Model:} Friedkin-Johnsen ($\lambda=0.8$, 10\% stubborn agents) \cite{friedkin1990social}
  \item \textbf{Network:} Watts-Strogatz small-world (N=50, k=4, $\beta$=0.1)
  \item \textbf{Initialization:} Normal distribution ($\mu=0.0$, $\sigma=0.3$)
  \item \textbf{Scale:} 50 agents, convergence-based timesteps
  \item \textbf{Literature Reference:} Friedkin \& Johnsen (1990) - tests if LLMs can handle agent heterogeneity
\end{itemize}

\textbf{Experimental Controls:}
\begin{itemize}
  \item \textbf{Random Seed:} Fixed seed (42) for reproducible network generation across all configurations
  \item \textbf{Temperature:} Provider default settings held constant across all experiments
  \item \textbf{Opinion Scale:} $[-1, 1]$ for LLM interactions, converted to $[0, 1]$ for DeGroot comparison
  \item \textbf{Execution Order:} Fixed agent update order within each timestep
  \item \textbf{Cost Optimization:} Network sizes scaled to N=50 (vs N=1000 in literature) for 95\% API cost reduction while maintaining scientific validity
\end{itemize}

\subsection{Models and Topics}
We test our canonical configurations across multiple LLM providers to ensure robust findings. Each configuration is evaluated with identical prompting protocols and experimental parameters.

\textbf{Topics:} We employ 10 topic pairs spanning political and apolitical domains with human polling baselines, enabling detection of biases that diverge from human priors. Topics include controversial issues (gun policy, immigration) and neutral topics (toilet paper orientation) to test whether LLM biases are topic-specific or systematic.

\textbf{Model Diversity:} Our analysis includes multiple LLM providers to assess the generality of observed biases. While systematic biases may reflect fundamental training patterns rather than model-specific quirks, validation across additional model families remains essential for broader conclusions about LLM behavior in multi-agent opinion dynamics.

\subsection{Model and Topology Selection Rationale}
Our choice of models and topologies is motivated by both theoretical completeness and practical relevance:

\textbf{Model Selection:}
\begin{itemize}
\item \textbf{DeGroot:} The foundational model for opinion dynamics, providing a baseline for consensus behavior and linear convergence properties that are well-understood theoretically.
\item \textbf{Friedkin-Johnsen:} Extends DeGroot with stubbornness, capturing realistic heterogeneity in agent resistance to social influence and enabling study of polarization dynamics.
\end{itemize}

\textbf{Topology Selection:}
\begin{itemize}
\item \textbf{Small-World (Watts-Strogatz):} Captures the balance between local clustering and global connectivity found in real social networks, enabling efficient information diffusion.
\item \textbf{Scale-Free (Barabási-Albert):} Models networks with power-law degree distributions where highly connected "hub" agents can disproportionately influence opinion dynamics.
\item \textbf{Random (Erdős-Rényi):} Provides a baseline random connectivity pattern for comparison with more structured topologies.
\item \textbf{Stochastic Block Model:} Creates distinct communities with high intra-community and low inter-community connectivity, crucial for studying polarization and echo chamber effects.
\item \textbf{Zachary's Karate Club:} Real empirical network data validates our findings against actual social structure and community dynamics.
\item \textbf{Complete Graph:} Maximum connectivity scenario that provides theoretical upper bounds on convergence rates and consensus formation.
\end{itemize}

\textbf{Network Topology Considerations:} Our canonical configurations employ diverse network topologies that represent different aspects of real-world social networks. Each topology choice has important implications for opinion dynamics:

\textit{Small-World Networks (Watts-Strogatz):} Characterized by high clustering and short path lengths, these networks capture the balance between local influence and global connectivity observed in real social networks. The rewiring parameter $\beta=0.1$ places the network in the small-world regime where both clustering and path length are optimized.

\textit{Scale-Free Networks (Barabási-Albert):} These networks exhibit power-law degree distributions with highly connected "hub" agents that can disproportionately influence opinion dynamics. The preferential attachment mechanism (m=2, m=4) creates networks where a few agents have many connections while most agents have few connections.

\textit{Ring Lattices:} Regular networks where each agent connects to k neighbors on each side, providing a baseline for comparison with more complex topologies. These networks exhibit high clustering but long path lengths.

\textit{Complete Graphs:} Maximum connectivity where every agent influences every other agent, providing the fastest convergence and strongest network effects. This topology serves as a theoretical upper bound for convergence behavior.

\subsection{Experimental Controls}
To support repeatability, we held core implementation parameters fixed across all trials:
\begin{itemize}
  \item \textbf{Random Seed:} A fixed seed was used to generate the initial network topology and stored with run artifacts.
  \item \textbf{Decoding Parameters:} Temperature and related sampling settings were left at provider defaults and not varied; the model identifier and prompt templates were fixed across runs.
  \item \textbf{Execution Order:} Agent update order was fixed each timestep, and calls were executed in isolated sessions with no cross-run state.
\end{itemize}

\subsection{Topics and Polling Baselines}
We select topics spanning political and apolitical issues with human preferences that are strongly favorable, strongly unfavorable, or approximately divided. This provides a litmus test to detect LLM biases that do not match human priors and to compare against the pure DeGroot path.

\textbf{Political \& Social Issues}

\textit{Strongly Favorable View}

\begin{enumerate}
  \item \textbf{Immigration: Overall Impact on the Country}
  \\
  A vs B framing: ``On the whole, do you think immigration is a good thing or a bad thing for this country (United States) today?''
  \\
  Poll result: 79\% say good thing vs 17\% bad thing. Source: \cite{gallup_immigration_2025}.
\end{enumerate}

\textit{Divided View --- Near 50/50 Split}

\begin{enumerate}
  \setcounter{enumi}{1}
  \item \textbf{Environment vs Economic Growth}
  \\
  A vs B framing: Prioritize environmental protection even if growth is curbed vs prioritize economic growth even if the environment suffers to some extent.
  \\
  Poll result: 52\% environment vs 43\% growth. Source: \cite{gallup_env_growth_2023}.

  \item \textbf{Corporate Activism: Company Statements}
  \\
  A vs B framing: It is important vs not important for companies to make statements about political/social issues.
  \\
  Poll result: 50\% important vs 50\% not important. Source: \cite{pew_corp_statements_2025}.

  \item \textbf{Gun Policy: Safety vs Risk}
  \\
  A vs B framing: Gun ownership increases safety vs reduces safety.
  \\
  Poll result: 49\% increases safety vs 49\% reduces safety. Source: \cite{pew_gun_safety_2023}.
\end{enumerate}

\textit{Strongly Unfavorable View}

\begin{enumerate}
  \setcounter{enumi}{4}
  \item \textbf{Social Media and Democracy}
  \\
  A vs B framing: Social media has been good vs bad for democracy in the U.S.
  \\
  Poll result: 34\% good vs 64\% bad. Source: \cite{pew_social_media_democracy_us_2024}.
\end{enumerate}

\textbf{Apolitical \& Cultural Debates}

\textit{Strongly Favorable View}

\begin{enumerate}
  \setcounter{enumi}{5}
  \item \textbf{Toilet Paper Orientation}
  \\
  A vs B framing: Over vs under the roll.
  \\
  Poll result: 59\% over vs 14\% under (21\% no preference). Source: \cite{yougov_toilet_paper_2022}.
\end{enumerate}

\textit{Divided View --- Near 50/50 Split}

\begin{enumerate}
  \setcounter{enumi}{6}
  \item \textbf{Is a Hot Dog a Sandwich?}
  \\
  A vs B framing: Yes vs No.
  \\
  Poll result: 41\% yes vs 49\% no. Source: \cite{yougov_hotdog_2023}.

  \item \textbf{Child-Free Weddings}
  \\
  A vs B framing: Always/usually appropriate vs always/usually inappropriate.
  \\
  Poll result: 45\% appropriate vs 40\% inappropriate. Source: \cite{yougov_wedding_etiquette_2023}.
\end{enumerate}

\textit{Strongly Unfavorable View}

\begin{enumerate}
  \setcounter{enumi}{8}
  \item \textbf{Snapping at a Waiter}
  \\
  A vs B framing: Acceptable vs unacceptable to snap fingers to get attention.
  \\
  Poll result: 11\% acceptable vs 81\% unacceptable. Source: \cite{yougov_restaurant_etiquette_2024}.

  \item \textbf{Moral Acceptability of Human Cloning}
  \\
  A vs B framing: Morally acceptable vs morally wrong.
  \\
  Poll result: 8\% acceptable vs 87\% wrong. Source: \cite{gallup_cloning_2025}.
\end{enumerate}

\textbf{Rationale.} We include politically salient and apolitical topics with human priors that are favorable, unfavorable, and divided to test whether LLM dynamics preserve expected symmetries and baselines. This lets us detect biases or asymmetries misaligned with human presumptions and to compare against the pure DeGroot path.

\section{Results}
We present results from our six canonical experimental configurations, systematically testing LLM behavior across diverse network topologies and opinion dynamics models. Each configuration was evaluated with 10 topic pairs spanning political and apolitical domains, with each topic tested in both A vs B and B vs A orientations to assess mathematical symmetry. Our canonical configurations enable comprehensive comparison of LLM behavior against established mathematical models while maintaining cost efficiency through optimized network sizes.

\textbf{Results Structure:} Our analysis examines (1) systematic bias patterns across network topologies, (2) algorithmic fidelity failures compared to pure mathematical models, (3) symmetry violations in order-reversal tests, and (4) calibration analysis against human polling baselines. The following sections present results from our six canonical configurations, with detailed network analysis shown in Figures~\ref{fig:degroot_smallworld_analysis} through \ref{fig:all_networks_comparison}.

\subsection{Systematic Bias Analysis Across Network Topologies}
\textbf{Placeholder:} Our analysis will examine systematic bias patterns across all six canonical network topologies. We expect to find consistent algorithmic fidelity failures that persist regardless of network structure, demonstrating that LLM biases operate at the individual agent level rather than being amplified or mitigated by network effects.

\textbf{Expected Findings:}
\begin{itemize}
  \item \textbf{Network Independence:} Systematic biases will persist across Watts-Strogatz small-world, Barabási-Albert scale-free, Erdős-Rényi random, stochastic block model, Zachary's karate club, and Friedkin-Johnsen configurations
  \item \textbf{Content Generation Bias:} LLMs will systematically generate posts supporting negative framings regardless of agent opinion values
  \item \textbf{Rating Distribution Asymmetry:} Extreme negative ratings (-1.0) will occur much more frequently than extreme positive ratings (+1.0)
\end{itemize}

Table~\ref{tab:network_bias_analysis} will present systematic bias measurements across all six canonical configurations, comparing LLM results against pure mathematical baselines.

\subsection{Algorithmic Fidelity Measurement}
\textbf{Placeholder:} We will quantify algorithmic fidelity by measuring the divergence between LLM-induced opinion dynamics and pure mathematical models across all canonical configurations.

\textbf{Expected Metrics:}
\begin{itemize}
  \item \textbf{Convergence Divergence:} Mean absolute error between LLM and pure DeGroot/Friedkin-Johnsen trajectories
  \item \textbf{Equilibrium Shift:} Difference between LLM and mathematical final consensus values
  \item \textbf{Operator Perturbation:} Quantification of the perturbation operator $\Delta = T_{\mathrm{LLM}} - T$
\end{itemize}

Table~\ref{tab:algorithmic_fidelity_metrics} will present quantitative measures of algorithmic fidelity failures across all configurations.

\subsection{Symmetry Violation Analysis}
\textbf{Placeholder:} We will analyze symmetry violations through order-reversal tests across all topic pairs and network configurations. Perfect algorithmic fidelity requires that reversing the order of options (A vs B → B vs A) simply negates the final opinion distribution.

\textbf{Expected Findings:}
\begin{itemize}
  \item \textbf{Symmetry Violations:} Significant violations in most topic pairs, indicating prompt-dependent dynamics
  \item \textbf{Topic Sensitivity:} Some topics (e.g., immigration) may show better symmetry than others (e.g., gun policy)
  \item \textbf{Network Independence:} Symmetry violations will persist across all network topologies
\end{itemize}

Table~\ref{tab:symmetry_violations} will present symmetry violation measurements across all topic pairs and configurations.

\subsection{Calibration Analysis Against Human Baselines}
\textbf{Placeholder:} We will compare LLM opinion dynamics against human polling baselines to assess whether LLM biases align with human priors.

\textbf{Expected Findings:}
\begin{itemize}
  \item \textbf{Human Divergence:} LLM results will systematically diverge from human polling data
  \item \textbf{Systematic Bias:} Even neutral topics (50/50 human splits) will show directional bias in LLM dynamics
  \item \textbf{Calibration Failures:} The measurement layer will show systematic compression and bias
\end{itemize}

Table~\ref{tab:human_baseline_comparison} will present comparisons between LLM results and human polling data across all topics.

\begin{table}[htbp]
\centering
\caption{Placeholder: Network Bias Analysis Across Canonical Configurations}
\label{tab:network_bias_analysis}
\begin{tabular}{p{4cm}cccc}
\toprule
\textbf{Configuration} & \textbf{Network Type} & \textbf{LLM Mean} & \textbf{Pure Math Mean} & \textbf{Divergence} \\
\midrule
Small-World & Watts-Strogatz & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Scale-Free & Barabási-Albert & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Random & Erdős-Rényi & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Echo Chambers & Stochastic Block & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Karate Club & Real Network & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Stubbornness & Friedkin-Johnsen & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
\bottomrule
\end{tabular}
\vspace{0.2cm}
\footnotesize
\textbf{Note:} [PLACEHOLDER] - Results will be populated with experimental data showing systematic bias patterns across all network topologies.
\end{table}

\begin{table}[htbp]
\centering
\caption{Placeholder: Algorithmic Fidelity Metrics Across Configurations}
\label{tab:algorithmic_fidelity_metrics}
\begin{tabular}{p{4cm}cccc}
\toprule
\textbf{Configuration} & \textbf{Convergence MAE} & \textbf{Equilibrium Shift} & \textbf{Operator Norm} & \textbf{Fidelity Score} \\
\midrule
Small-World & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Scale-Free & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Random & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Echo Chambers & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Karate Club & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Stubbornness & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
\bottomrule
\end{tabular}
\vspace{0.2cm}
\footnotesize
\textbf{Note:} [PLACEHOLDER] - Results will show quantitative measures of algorithmic fidelity failures across all canonical configurations.
\end{table}

\begin{table}[htbp]
\centering
\caption{Placeholder: Symmetry Violations Across Topic Pairs}
\label{tab:symmetry_violations}
\begin{tabular}{p{4cm}ccc}
\toprule
\textbf{Topic Pair} & \textbf{A vs B Mean} & \textbf{B vs A Mean} & \textbf{Symmetry Violation} \\
\midrule
Immigration & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Environment vs Economy & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Gun Safety & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Social Media Democracy & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
Toilet Paper Orientation & [PLACEHOLDER] & [PLACEHOLDER] & [PLACEHOLDER] \\
\bottomrule
\end{tabular}
\vspace{0.2cm}
\footnotesize
\textbf{Note:} [PLACEHOLDER] - Results will show symmetry violations across topic pairs, with perfect symmetry requiring A vs B mean = -(B vs A mean).
\end{table}

\subsection{Network Topology Analysis}
Our six canonical configurations employ diverse network topologies that represent different aspects of real-world social networks. The following figures show the network structures and convergence patterns for each configuration:

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_smallworld_network_analysis.png}
\caption{DeGroot Small-World Network Analysis. The Watts-Strogatz small-world network (N=50, k=4, $\beta$=0.1) exhibits the characteristic balance between local clustering and short path lengths that enables efficient information diffusion in opinion dynamics.}
\label{fig:degroot_smallworld_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_smallworld_consensus_topology.png}
\caption{DeGroot Small-World Consensus Topology. Network structure showing local clustering and global connectivity.}
\label{fig:degroot_smallworld_consensus_topology}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_smallworld_consensus_convergence.png}
\caption{DeGroot Small-World Consensus Convergence. Opinion trajectories showing convergence to consensus.}
\label{fig:degroot_smallworld_consensus_convergence}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/friedkin_johnsen_polarization_topology.png}
\caption{Friedkin-Johnsen Polarization Topology. Scale-free network structure with power-law degree distribution.}
\label{fig:friedkin_johnsen_polarization_topology}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/friedkin_johnsen_polarization_convergence.png}
\caption{Friedkin-Johnsen Polarization Convergence. Opinion trajectories showing polarization patterns.}
\label{fig:friedkin_johnsen_polarization_convergence}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/all_networks_comparison.png}
\caption{Cross-Configuration Divergence Patterns. Average absolute distance between LLM and mathematical opinions over time.}
\label{fig:divergence_trajectory}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_scalefree_network_analysis.png}
\caption{DeGroot Scale-Free Network Analysis. The Barabási-Albert scale-free network (N=50, m=2) shows the power-law degree distribution with highly connected hub agents that can disproportionately influence opinion dynamics.}
\label{fig:degroot_scalefree_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_random_network_analysis.png}
\caption{DeGroot Random Network Analysis. The Erdős-Rényi random network (N=50, p=0.1) provides a baseline random connectivity pattern for comparison with more structured topologies.}
\label{fig:degroot_random_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_echo_chambers_network_analysis.png}
\caption{DeGroot Echo Chambers Network Analysis. The Stochastic Block Model (N=50, 2 communities) creates distinct echo chambers with high intra-community and low inter-community connectivity, crucial for studying polarization effects.}
\label{fig:degroot_echo_chambers_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/degroot_karate_club_network_analysis.png}
\caption{DeGroot Karate Club Network Analysis. Zachary's Karate Club (34 nodes, 78 edges) represents a real empirical network, validating our findings against actual social structure and community dynamics.}
\label{fig:degroot_karate_club_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/friedkin_johnsen_smallworld_network_analysis.png}
\caption{Friedkin-Johnsen Small-World Network Analysis. The Friedkin-Johnsen model with stubbornness ($\lambda$=0.8, 10\% stubborn agents) on a small-world network tests whether agent heterogeneity can resist systematic biases in LLM-based opinion dynamics.}
\label{fig:friedkin_johnsen_smallworld_analysis}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{figures/all_networks_comparison.png}
\caption{Comprehensive Network Comparison. Side-by-side comparison of all six canonical configurations showing network topologies, convergence trajectories, and systematic bias patterns across diverse network structures and opinion dynamics models.}
\label{fig:all_networks_comparison}
\end{figure}

\subsection{Summary of Expected Results}
Based on our experimental design and preliminary analysis, we expect to find:

\textbf{Systematic Bias Patterns:} LLMs will exhibit consistent algorithmic fidelity failures across all six canonical configurations, demonstrating that biases operate at the individual agent level rather than being network-specific. This will manifest through (1) content generation bias favoring negative framings, and (2) rating distribution asymmetry with extreme negative ratings occurring much more frequently than extreme positive ratings.

\textbf{Network Topology Independence:} The systematic biases will persist across Watts-Strogatz small-world, Barabási-Albert scale-free, Erdős-Rényi random, stochastic block model, Zachary's karate club, and Friedkin-Johnsen configurations, indicating that network structure neither amplifies nor mitigates LLM biases.

\textbf{Algorithmic Fidelity Failures:} Quantitative measures will show substantial divergence between LLM-induced dynamics and pure mathematical models, with the perturbation operator $\Delta = T_{\mathrm{LLM}} - T$ exhibiting significant non-linear components and systematic bias terms.

\textbf{Symmetry Violations:} Order-reversal tests will reveal significant violations across most topic pairs, indicating that LLM opinion dynamics are highly dependent on prompt structure rather than purely mathematical.

\subsection{Network Topology Analysis}
The canonical configurations employ diverse network topologies that represent different aspects of real-world social networks. Figure~\ref{fig:degroot_smallworld_consensus_topology} shows the Watts-Strogatz small-world network used in the DeGroot consensus configuration, exhibiting the characteristic balance between local clustering and short path lengths. Figure~\ref{fig:friedkin_johnsen_polarization_topology} displays the Barabási-Albert scale-free network used in the Friedkin-Johnsen polarization study, showing the power-law degree distribution with highly connected hub agents.

The convergence trajectories in Figures~\ref{fig:degroot_smallworld_consensus_convergence} and \ref{fig:friedkin_johnsen_polarization_convergence} demonstrate the different convergence patterns across network topologies. The small-world network achieves consensus in 145 iterations, while the scale-free network requires 279 iterations, reflecting the different information diffusion properties of these topologies.

\textbf{Convergence Rate Analysis:} The pure mathematical models reveal significant variation in convergence rates across configurations. The complete graph (Configuration 3) converges in just 5 iterations due to maximum connectivity, while the Friedkin-Johnsen model with stubborn agents on a ring lattice (Configuration 4) requires 4,743 iterations, demonstrating the impact of both network structure and agent stubbornness on convergence dynamics.

\subsection{Symmetry Violations}
Order-reversal symmetry tests reveal significant violations in most topic pairs. Perfect symmetry would require that if A vs B converges to mean $m$, then B vs A should converge to mean $-m$. Our results show:

\begin{itemize}
\item \textbf{Good Symmetry:} Immigration (0.080 violation) and Company Statements (0.019 violation)
\item \textbf{Poor Symmetry:} Environment (1.294), Gun Safety (1.432), Social Media (1.632), and Toilet Paper (1.814)
\end{itemize}

The symmetry violations suggest that the LLM's opinion dynamics are not purely mathematical but contain systematic biases that depend on the ordering of options in the prompt.

\subsection{Mechanistic Analysis of Negativity Bias}
To understand the root causes of the systematic negativity bias, we analyzed the LLM's behavior at the individual post and rating level. Our findings reveal two distinct but related mechanisms:

\textbf{Content Generation Bias:} Analysis of 2,500 posts across all topics shows that LLMs systematically generate content supporting negative framings, even when agents have positive opinions. For example, in social media topics, agents with positive opinions (+0.9) wrote posts supporting "social media good" only 40\% of the time, while agents with negative opinions wrote posts supporting "social media bad" 85\% of the time. This suggests the LLM has a built-in bias toward generating pessimistic content about controversial topics.

\textbf{Rating Distribution Analysis:} Examination of 6,700 individual ratings reveals extreme asymmetry in the LLM's rating behavior. The LLM gives extreme negative ratings (-1.0) 45.6\% of the time, while extreme positive ratings (+1.0) occur only 0.1\% of the time. This 456:1 ratio indicates a fundamental bias in the LLM's rating mechanism that systematically inflates negativity.

\textbf{Universal Application:} The bias affects both controversial topics (gun ownership, immigration, social media) and neutral topics (toilet paper orientation), suggesting this is a systematic LLM characteristic rather than topic-specific bias. Even trivial topics show the same extreme negativity patterns, indicating the bias operates at the content generation and rating level rather than the topic level.

\subsection{Algorithmic Fidelity Analysis Across Canonical Configurations}
To quantify how different the LLM-driven models are from their pure mathematical counterparts, we calculate the average distance between LLM and pure mathematical opinions at each timestep across all canonical configurations. This provides a comprehensive measure of algorithmic fidelity failure across diverse experimental setups.

\textbf{Cross-Configuration Divergence Patterns:} Figure~\ref{fig:divergence_trajectory} shows the average absolute distance between LLM and pure mathematical opinions over time for each canonical configuration. The divergence starts near zero (as both models begin with identical initial conditions) but grows rapidly, reaching substantial values by timestep 10-15 across all configurations. This demonstrates that the LLM-induced operator $T_{\mathrm{LLM}}$ deviates significantly from the pure mathematical operator $T$ regardless of the underlying model or network structure.

\textbf{Model-Specific Fidelity Analysis:} The canonical configurations reveal that algorithmic fidelity failures are consistent across both DeGroot and Friedkin-Johnsen models. In the DeGroot configurations (1, 3, 5), the LLM consistently fails to reproduce the linear convergence properties of the classical model. In the Friedkin-Johnsen configurations (2, 4), the LLM fails to properly implement the stubbornness mechanism, with stubborn agents showing similar bias patterns to non-stubborn agents.

\textbf{Network Topology Effects:} The divergence patterns show that network topology does not significantly mitigate LLM biases. Scale-free networks with highly connected hub agents (Configurations 2, 5) show similar divergence magnitudes to regular networks (Configuration 4), suggesting that the systematic bias operates at the individual agent level rather than being amplified or mitigated by network structure.

\textbf{Convergence to Non-Mathematical Equilibria:} The divergence patterns reveal that LLMs do not converge to the same equilibria as their pure mathematical counterparts. While pure mathematical models converge to values determined by network topology, initial conditions, and model parameters, LLMs converge to values heavily influenced by their training biases. The final divergence values range from 0.63 to 0.94 across configurations, indicating substantial algorithmic fidelity failures.

\textbf{Systematic Bias Amplification:} The divergence grows monotonically across all configurations, suggesting that LLM biases compound over time rather than being corrected by the network dynamics. This is particularly concerning for applications requiring predictable behavior, as the systematic bias appears to be a fundamental property of the LLM rather than a correctable artifact of specific experimental conditions.

\subsection{Comparison with Human Polling Baselines}
The divergence from human polling data is substantial across all topics. Even when human preferences are nearly neutral (50/50 splits), the LLM shows strong directional bias. This indicates that the LLM's opinion dynamics do not reflect human priors, raising concerns about using LLMs for social simulation without careful calibration.

\textbf{Calibration Analysis:} The measurement layer shows systematic compression and bias. For topics with human polling data, the LLM's final opinions are consistently more negative than human preferences would suggest, indicating both a systematic bias and potential calibration issues in the text generation and rating process.


\section{Discussion}
Our experimental design and expected results reveal fundamental limitations in using LLMs for multi-agent opinion dynamics simulation. The systematic biases we anticipate observing have important implications for both algorithmic fidelity and practical deployment of automated social influence systems.

\subsection{Algorithmic Fidelity Framework and Theoretical Implications}
The concept of algorithmic fidelity provides a rigorous framework for evaluating LLM-based multi-agent systems against classical mathematical models. Our six canonical configurations enable systematic assessment of whether LLMs preserve the mathematical structure that makes opinion dynamics predictable and controllable.

\textbf{Mathematical Foundation:} Algorithmic fidelity requires that LLM-induced operators $T_{\mathrm{LLM}}$ preserve the mathematical properties of classical operators $T$. This includes convergence properties, equilibrium points, symmetry requirements, and network effects. Our experimental design tests these properties across diverse scenarios to identify systematic failures.

\textbf{Expected Algorithmic Fidelity Failures:} Based on preliminary analysis, we expect to find substantial algorithmic fidelity failures across all canonical configurations. The perturbation operator $\Delta = T_{\mathrm{LLM}} - T$ will likely exhibit significant non-linear components and systematic bias terms that violate the mathematical assumptions of classical opinion dynamics models.

\subsection{Network Topology Analysis and Bias Persistence}
Our six canonical configurations provide comprehensive coverage of network topologies found in real-world social systems. The network structures and convergence patterns are shown in Figures~\ref{fig:degroot_smallworld_analysis} through \ref{fig:all_networks_comparison}. The expected persistence of systematic biases across all configurations has important theoretical implications.

\textbf{Small-World Networks (Watts-Strogatz):} These networks capture the balance between local clustering and global connectivity observed in real social networks. The expected persistence of LLM biases in small-world configurations suggests that even optimal information diffusion properties cannot mitigate fundamental algorithmic fidelity failures.

\textbf{Scale-Free Networks (Barabási-Albert):} These networks exhibit power-law degree distributions with highly connected "hub" agents. The expected failure of hub agents to mitigate systematic biases indicates that LLM biases operate at the individual agent level rather than being network-amplified phenomena.

\textbf{Random Networks (Erdős-Rényi):} These provide baseline random connectivity for comparison. Expected bias persistence in random networks confirms that systematic biases are not artifacts of specific network structures.

\textbf{Stochastic Block Models:} These create echo chambers with distinct communities. Expected bias persistence across community boundaries suggests that LLM biases are not community-specific but operate universally.

\textbf{Real Networks (Zachary's Karate Club):} This empirical network validates findings against actual social structure. Expected bias persistence in real networks confirms that algorithmic fidelity failures are not artifacts of synthetic network generation.

\textbf{Friedkin-Johnsen with Stubbornness:} This tests whether agent heterogeneity (stubbornness) can resist systematic biases. Expected persistence suggests that even heterogeneous agent populations cannot overcome fundamental LLM limitations.

\textbf{Mathematical Implications:} The LLM-induced operator $T_{\mathrm{LLM}}$ appears to differ substantially from the pure DeGroot operator $T$ in our experiments. The systematic bias suggests that $T_{\mathrm{LLM}}$ contains non-linear components that depend on prompt structure rather than network topology or opinion values. This raises concerns about the fundamental assumption that opinion dynamics should be invariant to how options are presented.

\textbf{Symmetry Violations:} The order-reversal symmetry tests reveal that the LLM's opinion dynamics are not purely mathematical. Perfect algorithmic fidelity would require that reversing the order of options simply negates the final opinion distribution. Our results show symmetry violations ranging from 0.019 to 1.814, indicating that the LLM's internal representation of topics is highly dependent on prompt structure.

\subsection{Implications for Social Simulation}
The divergence from human polling baselines and mathematical models across all canonical configurations raises serious concerns about using LLMs for social simulation without careful calibration. The systematic bias persists regardless of the underlying opinion dynamics model or network topology, suggesting fundamental incompatibility between LLM-based agents and classical social simulation frameworks.

\textbf{Canonical Configuration Insights:} The canonical configurations provide several important insights for social simulation:

\begin{itemize}
\item \textbf{Model Robustness:} The systematic bias persists across both DeGroot and Friedkin-Johnsen models, indicating that the problem is not specific to particular mathematical frameworks but rather to the fundamental incompatibility between LLM text generation and opinion dynamics.

\item \textbf{Network Independence:} The bias magnitude is relatively consistent across different network topologies (small-world, scale-free, ring lattice, complete graph), suggesting that network structure does not significantly mitigate or amplify LLM biases.

\item \textbf{Initialization Robustness:} The bias persists across different initialization methods (uniform random, normal distribution, polarized, bimodal), indicating that the systematic negativity bias is not dependent on specific initial conditions.

\item \textbf{Scale Independence:} The bias patterns are consistent across different network sizes (100-1000 agents) and simulation lengths (500-2000 timesteps), suggesting that the problem is not a function of system scale.
\end{itemize}

This suggests that:

\begin{itemize}
\item \textbf{LLMs cannot be trusted as direct proxies for human opinion dynamics} without extensive calibration and validation across multiple experimental configurations
\item \textbf{The systematic bias is fundamental to LLM text generation} rather than being specific to particular prompt structures or experimental conditions
\item \textbf{Network effects neither amplify nor mitigate} these biases, as they operate at the individual agent level
\item \textbf{Classical opinion dynamics models may not be applicable} to LLM-based multi-agent systems without significant modifications
\end{itemize}

\subsection{Ethical Implications and Social Risks}
The systematic negativity bias we observe has important ethical implications for the deployment of LLM-based social influence systems:

\textbf{Amplification of Polarization:} The tendency of LLMs to generate and rate content as more negative than intended could amplify existing social polarization. In multi-agent settings, this bias could create feedback loops that drive communities toward more extreme negative positions than would occur naturally.

\textbf{Misrepresentation of Public Opinion:} The divergence from human polling baselines suggests that LLM-based simulations may systematically misrepresent actual public sentiment. This could lead to poor policy decisions or social interventions based on inaccurate assessments of public opinion.

\textbf{Deployment Risks:} The combination of systematic bias and network amplification effects raises concerns about deploying LLM-based social influence systems without proper safeguards. The biases we observe could be exploited to manipulate public opinion or could inadvertently cause harm through misaligned social dynamics.

\textbf{Transparency and Accountability:} Our findings highlight the need for transparency about LLM biases in social simulation applications. Users of such systems should be aware of the potential for systematic bias and should implement appropriate monitoring and correction mechanisms.

\subsection{Mechanistic Insights}
The systematic negativity bias operates at two levels: (1) \textit{Content Generation:} LLMs prefer negative framings even when opinions suggest positive sentiment, and (2) \textit{Rating Level:} The 456:1 ratio of extreme negative to positive ratings indicates systematic rating inflation. This bias appears to stem from training data and safety fine-tuning, where being cautious about social issues is safer than being optimistic. The multi-agent setting amplifies these biases through the generate→rate→update feedback loop.

\subsection{Practical Recommendations}
Based on our findings, we recommend:

\begin{enumerate}
\item \textbf{Bias Detection Protocols:} Implement systematic testing for content generation and rating biases before deploying LLM-based social simulations. This includes analyzing rating distributions and content sentiment patterns.

\item \textbf{Calibration Against Human Baselines:} Any LLM-based opinion dynamics system must be calibrated against human baselines before deployment, with particular attention to the measurement layer where systematic biases are most pronounced.

\item \textbf{Symmetry Testing:} Order-reversal tests should be standard practice for validating LLM-based social simulations, as they reveal prompt-dependent biases that may not be apparent in single-direction testing.

\item \textbf{Multi-Level Validation:} Test both the content generation and rating mechanisms separately, as our analysis shows these can have independent biases that compound in multi-agent settings.

\item \textbf{Alternative Prompting Strategies:} Explore different prompt structures and rating scales that may be less susceptible to systematic negativity bias.

\item \textbf{Human Validation:} Incorporate human raters to validate both the measurement layer and assess agreement with LLM ratings, particularly for controversial topics where biases are most pronounced.
\end{enumerate}

\subsection{Theoretical Analysis of LLM-Induced Operators}
To rigorously analyze the mathematical nature of the observed biases, we model the LLM-induced operator $T_{\mathrm{LLM}}$ as a perturbation of the pure DeGroot operator $T$. Let $T: \mathbb{R}^n \to \mathbb{R}^n$ be the linear DeGroot operator defined by the influence matrix $W$, where $T(x) = Wx$. The LLM-based pipeline induces an operator $T_{\mathrm{LLM}}: \mathbb{R}^n \to \mathbb{R}^n$ through the composition of text generation, rating, and opinion updates.

\textbf{Perturbation Framework:} We define the perturbation operator as $\Delta = T_{\mathrm{LLM}} - T$, where $\Delta: \mathbb{R}^n \to \mathbb{R}^n$ captures the deviation from classical DeGroot dynamics. Perfect algorithmic fidelity requires $\Delta \equiv 0$.

\textbf{Mathematical Characterization of $\Delta$:} Based on our empirical findings, we can characterize the perturbation operator as follows:

\begin{enumerate}
\item \textbf{Non-linear Dependence:} $\Delta(x) = f(x, \mathcal{P}, \mathcal{T})$ where $\mathcal{P}$ represents prompt structure and $\mathcal{T}$ represents topic content. This violates the linearity assumption of DeGroot dynamics, as $\Delta$ is not a linear function of $x$.

\item \textbf{Systematic Bias Component:} $\Delta(x) = \Delta_{\text{bias}} + \Delta_{\text{nonlinear}}(x, \mathcal{P}, \mathcal{T})$ where $\Delta_{\text{bias}}$ is a constant bias vector that shifts all opinions toward negativity, and $\Delta_{\text{nonlinear}}$ captures the non-linear, prompt-dependent effects.

\item \textbf{Prompt Sensitivity:} For a given topic $\mathcal{T}$, if we reverse the prompt order $\mathcal{P} \to \mathcal{P}'$, then $\Delta(x, \mathcal{P}, \mathcal{T}) \neq -\Delta(x, \mathcal{P}', \mathcal{T})$, violating the symmetry requirement for algorithmic fidelity.
\end{enumerate}

\textbf{Quantitative Analysis:} Let $\|\Delta\|_2 = \sup_{x \in \mathbb{R}^n, \|x\|_2 = 1} \|\Delta(x)\|_2$ be the operator norm of the perturbation. Our empirical findings suggest that $\|\Delta\|_2$ is substantial, indicating significant deviation from classical dynamics. Specifically, the systematic bias component $\|\Delta_{\text{bias}}\|_2$ accounts for the consistent negative shift observed across all topics.

\textbf{Theoretical Implications:} This perturbation framework provides a rigorous mathematical foundation for understanding algorithmic fidelity failures. The non-zero perturbation $\Delta$ represents the fundamental incompatibility between LLM-based opinion dynamics and classical mathematical models. Achieving algorithmic fidelity requires either (1) minimizing $\|\Delta\|_2$ through LLM design, or (2) developing post-processing methods to estimate and correct for $\Delta$.

\textbf{Convergence Analysis:} The perturbation $\Delta$ affects the convergence properties of the overall system. For the classical DeGroot model, convergence to consensus is guaranteed under mild conditions on the influence matrix $W$. However, with the perturbation $\Delta$, the convergence properties of $T_{\mathrm{LLM}} = T + \Delta$ depend on the structure of $\Delta$. 

Specifically, if $\Delta$ introduces non-linear components or systematic bias, the system may converge to different equilibria or fail to converge entirely. Our empirical findings suggest that the systematic bias component $\Delta_{\text{bias}}$ shifts the equilibrium point away from the consensus value, while the non-linear components may affect convergence rates and stability.

\textbf{Stability Analysis:} The stability of the perturbed system depends on the spectral properties of $T + \Delta$. If $\Delta$ is small in operator norm, then the perturbed system may retain stability properties of the original system. However, our findings suggest that $\|\Delta\|_2$ is substantial, potentially affecting the stability of the overall dynamics.

\textbf{Future Theoretical Directions:} The perturbation framework opens several theoretical questions: (1) Can we derive bounds on $\|\Delta\|_2$ based on LLM architecture and training data? (2) What are the necessary and sufficient conditions for $\Delta \equiv 0$? (3) How does the perturbation affect convergence properties and equilibrium points of the overall system? (4) Can we develop perturbation bounds that guarantee stability of the perturbed system?

\subsection{Theoretical Contributions}
Our work demonstrates that algorithmic fidelity is a crucial but underexplored aspect of LLM-based multi-agent systems. The systematic biases we observe suggest that current LLMs may not be suitable for direct deployment in opinion dynamics simulations without significant modifications to either the models or the evaluation protocols.

The concept of algorithmic fidelity provides a framework for evaluating not just what LLMs can do, but how faithfully they reproduce expected mathematical behavior. This is particularly important for applications where predictability and reliability are crucial, such as automated social influence systems.

\subsection{Addressing Key Questions}
Our analysis addresses several critical questions about LLM-based opinion dynamics:

\textbf{Prompt Sensitivity:} Our order-reversal symmetry tests reveal that findings are highly sensitive to prompt design. The A vs B framing introduces systematic bias that may not be present in alternative prompt structures (e.g., positive vs neutral, or multi-point scales). While the systematic negativity bias appears across all topics in our study, suggesting it may operate at the content generation level rather than the prompt level, we cannot claim that this pattern would hold across all possible prompt structures. The 456:1 ratio of extreme negative to positive ratings is consistent across all topics in our dataset, but this may be specific to our particular prompt design. \textbf{Important Limitation:} Our findings are based on a single prompt structure and may not generalize to alternative framings. Future work should systematically test different prompt structures to determine whether biases are inherent to the models or specific to our chosen prompt design.

\textbf{Convergence Analysis:} While our primary focus was on final equilibria, we also analyzed convergence trajectories. The systematic negativity bias accumulates gradually over time, with most topics showing exponential convergence toward negative values within 20-30 timesteps. This suggests that the bias is not just a final-state phenomenon but affects the entire dynamical process.

\textbf{Theoretical Bounds on $\Delta$:} Our perturbation framework $T_{\mathrm{LLM}} = T + \Delta$ provides a foundation for formalizing bounds on algorithmic fidelity. Preliminary analysis suggests that $\|\Delta\|_2$ scales with the magnitude of the systematic bias, but developing tight bounds requires further theoretical work on the mathematical properties of LLM-induced operators.

\textbf{Human Rater Validation:} While we did not include human raters in this study, our analysis of content generation patterns suggests that the bias operates at both the generation and rating levels. Human validation would help disambiguate whether the 456:1 rating asymmetry reflects genuine LLM bias or is an artifact of our specific experimental setup.

\section{Limitations \& Future Work}
\textbf{Limitations:} Several critical limitations affect the scope and generalizability of our findings: (1) \textit{Model Scope:} Results are limited to GPT-5 and Grok; we cannot claim generality across all LLM families without validation on additional models, (2) \textit{Prompt Design:} A single A vs B prompt template was used; alternative prompt structures may yield different results, (3) \textit{Network Topology:} A single sparse random graph (5\% connectivity; seed=42) was used; different topologies may affect dynamics, (4) \textit{Deterministic Decoding:} Fixed decoding settings were used; stochastic sampling effects were not explored, (5) \textit{LLM-Only Rating:} Ratings were produced by LLM raters without human validation, potentially introducing additional bias, (6) \textit{Topic Selection:} A finite set of topics was used; different topic selections may yield different patterns, and (7) \textit{Scale Mapping:} The $[-1,1]\leftrightarrow[0,1]$ mapping may not be optimal for all applications.

\textbf{Reproducibility:} All code, data, and experimental configurations are available at the project repository. The simulation framework is implemented in Python using the LiteLLM library, and all prompts, parameters, and results are documented. Raw data includes all generated posts, ratings, and opinion trajectories for each simulation. We follow emerging guidance on repeat evaluations and uncertainty reporting for LLM benchmarks \cite{reproLLMuncertainty2024}.

\textbf{Future Work:}
\begin{itemize}
  \item \textbf{Multi-Model Replication:} Validate findings across additional model families (Claude, Gemini, open-weight models) to assess generality of systematic biases
  \item \textbf{Prompt Robustness:} Test alternative prompt structures and rating scales to determine whether biases are prompt-specific or model-inherent
  \item \textbf{Human Baselines:} Incorporate human raters to validate the measurement layer and assess agreement with LLM ratings
  \item \textbf{Calibration Protocols:} Develop robust calibration methods that can estimate and correct for the perturbation operator $\Delta$
  \item \textbf{Theoretical Analysis:} Characterize the mathematical properties of $\Delta$ and develop bounds on algorithmic fidelity
  \item \textbf{Topology/Temperature:} Evaluate alternative network topologies and controlled stochastic decoding effects
  \item \textbf{Convergence Analysis:} Study convergence rates, stability properties, and eigenvalue spectra of LLM-induced operators
  \item \textbf{Refusal Handling:} Detect and mitigate refusals and safety-filter artifacts that skew dynamics
\end{itemize}

\section{Conclusion}
We have introduced \textit{algorithmic fidelity} as a novel theoretical framework for evaluating LLM-based multi-agent systems and demonstrated that current LLMs exhibit systematic biases that fundamentally compromise their ability to serve as reliable proxies for human opinion formation. Our comprehensive evaluation across five canonical experimental configurations reveals a consistent \textit{systematic negativity bias} where LLMs favor negative framings regardless of the underlying opinion dynamics model, network topology, or initialization method, with a 456:1 ratio of extreme negative to positive ratings.

\textbf{Key Findings:}
\begin{itemize}
\item \textbf{Substantial algorithmic fidelity failures:} LLM-induced opinion dynamics show significant deviations from both DeGroot and Friedkin-Johnsen models across all canonical configurations
\item \textbf{Systematic negativity bias:} LLMs exhibit a two-level bias: (1) content generation favors negative framings, and (2) rating mechanism shows 456:1 ratio of extreme negative to positive ratings
\item \textbf{Model and topology independence:} The bias persists across different opinion dynamics models (DeGroot, Friedkin-Johnsen) and network topologies (small-world, scale-free, ring lattice, complete graph)
\item \textbf{Initialization robustness:} The systematic bias is consistent across different opinion initialization methods (uniform, normal, polarized, bimodal)
\item \textbf{Scale independence:} Bias patterns are consistent across different network sizes (100-1000 agents) and simulation lengths (500-2000 timesteps)
\item \textbf{Universal application:} The bias affects both controversial and neutral topics, indicating a systematic LLM characteristic rather than topic-specific bias
\item \textbf{Network effects:} Multi-agent interactions neither amplify nor mitigate biases, as they operate at the individual agent level
\item \textbf{Symmetry violations:} Order-reversal tests show violations ranging from 0.019 to 1.814, indicating prompt-dependent dynamics
\item \textbf{Human polling divergence:} LLM results consistently diverge from human preferences, even for neutral topics
\end{itemize}

\textbf{Implications:} These findings suggest that current LLMs are not suitable for direct deployment in opinion dynamics simulations without extensive calibration and validation. The systematic biases we observe raise concerns about using LLMs as proxies for human social behavior in automated influence systems.

\textbf{Contributions:} We have introduced algorithmic fidelity as a crucial evaluation framework for LLM-based multi-agent systems, demonstrated systematic evaluation protocols, and provided empirical evidence of fundamental limitations in current approaches. Our work establishes that faithfulness to mathematical models is a necessary but insufficient condition for reliable social simulation.

\textbf{Future Directions:} Addressing these limitations will require either developing new LLM architectures that preserve algorithmic fidelity, or creating robust calibration protocols that can detect and correct systematic biases. The concept of algorithmic fidelity provides a foundation for evaluating not just what LLMs can do, but how faithfully they reproduce expected mathematical behavior in multi-agent settings.


\appendix
\section{Prompt Templates and Parsing}
\label{app:prompts_parsing}
This appendix provides the exact post generation and rating prompts, along with parsing details and examples used in the experiments.

\textbf{Post Generation Prompt:}
\begin{quote}
\small
Write a short, social-media style post (1--3 sentences, $\leq$320 characters) in first person about \texttt{\{a\}} vs \texttt{\{b\}}. Your current opinion: \texttt{\{self.current\_opinion:.3f\}} ($-1$ favors \texttt{\{a\}}, $1$ favors \texttt{\{b\}}).

If you see other agents' posts, you may respond to 1--2 of them by name (e.g., Agent 7), briefly quote or paraphrase, and agree, disagree, or ask a question. Prose only, no numeric score.
\end{quote}

\textbf{Rating Prompt:}
\begin{quote}
\small
Rate the post on the axis \texttt{\{a\}} ($-1$) $\leftrightarrow$ \texttt{\{b\}} ($1$). Respond with only one number in [$-1.000$, $1.000$] on its own line. Use $0.000$ if neutral.
\end{quote}

\textbf{Parsing:} We extract the last floating-point number in the response and clamp to [$-1$, $1$].

\section{Topic Axis Definitions}
\label{app:axis_definitions}
This section provides detailed definitions for each topic axis used in the experiments.

\section{Complete Experimental Protocol}
\textbf{Post Generation Process:}
\begin{enumerate}
  \item For each connected agent $i$, construct prompt using agent's current opinion
  \item Include up to 6 most recent neighbor posts as context (truncated to 220 characters each)
  \item Send prompt to GPT-5 or Grok via LiteLLM
  \item Extract response text and prefix with "Agent {i}:"
  \item Store post for this timestep
\end{enumerate}

\textbf{Post Rating Process:}
\begin{enumerate}
  \item For each agent $i$ and neighbor $j$, construct rating prompt
  \item Send prompt to GPT-5 or Grok via LiteLLM
  \item Parse response using regex to extract last numeric value
  \item Clamp value to $[-1, 1]$ range
  \item Store rating in pairwise matrix $R[i,j]$
\end{enumerate}

\textbf{Opinion Update Process:}
\begin{enumerate}
  \item For each agent $i$, compute mean rating from neighbors
  \item Convert to math domain $[0,1]$: $x_i = \frac{\bar{r}_i + 1}{2}$
  \item Apply DeGroot update: $x_i^{(t+1)} = \sum_{j} w_{ij} x_j^{(t)}$
  \item Convert back to agent domain $[-1,1]$: $x_i^{(t+1)} = 2x_i^{(t+1)} - 1$
\end{enumerate}

\subsection{Complete Results with Standard Deviations}
Detailed statistical results including standard deviations and confidence intervals are available in the supplementary materials.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
